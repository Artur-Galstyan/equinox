{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3edcc82e-6aeb-4fb5-8ad6-fb11cfab078d",
   "metadata": {},
   "source": [
    "# AlexNet & CommonLoopUtils\n",
    "\n",
    "In this example, we will implement [AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) and also use [CommonLoopUtils](https://github.com/google/CommonLoopUtils) from Google to track the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95912aa-d636-4ed7-9283-babf1c2059ac",
   "metadata": {},
   "source": [
    "## Short (and skippable) Introduction\n",
    "\n",
    "AlexNet is a CNN model from 2012, which arguably brought the \"deep\" to deep learning. It trained on ImageNet, which is a massive dataset consisting of over 15 million images and over 22000 classes and before AlexNet, that dataset was a tough nut to crack! To solve that dataset, the authors brought a few novelties to the table, some of which we will, skip. Those were:\n",
    "\n",
    "- Using ReLU (instead of Sigmoid), which boosted performance, speed and addressed the vanishing gradient problem\n",
    "- Multi GPU training (we will skip this, but they wrote a bunch of custom CUDA code to train the whole thing on TWO whole GPUs! Outrageous at that time)\n",
    "- Local Response Normalisation (largely superseded by Batch Normalisation these days, but still interesting)\n",
    "- Overlapping Max Pooling (basically using a stride of 2 instead of 1)\n",
    "- Dropout to prevent overfitting\n",
    "- a bunch of data augmentation:\n",
    "    - crop the image to 256x256\n",
    "    - select random 224x224 portion of the cropped image (we will do something similar)\n",
    "    - randomly flip the image horizontally\n",
    "    - PCA colour augmentation\n",
    "\n",
    "None of these were solely their invention (except for the normalisation method and the multi GPU stuff) but the combination of all these techniques is what wrote history. \n",
    "\n",
    "In this example, though, we won't be training on the ImageNet dataset, but instead on the `cats_vs_dogs` dataset, which is much harder than MNIST, but still small enough that you can train the thing in a relatively short amount of time (~30 minutes on a 3090)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
